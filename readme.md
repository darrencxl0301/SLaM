# EdgeLLM: Full-Stack Small Language Model Framework

<div align="center">

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-green.svg)](LICENSE)
[![Models: 13+](https://img.shields.io/badge/Models-13%2B%20SLMs-purple)](#supported-models)
[![Hardware: Edge](https://img.shields.io/badge/Hardware-Edge%20Deployment-green)](#hardware-requirements)

*Enterprise-grade Small Language Models on consumer hardware*

**Three Powerful Modules**: RAG + LoRA + Structured Querying

</div>

---

## ğŸ¯ What is EdgeLLM?

**EdgeLLM** is a complete, production-ready framework for deploying **Small Language Models (0.5B-14B)** on edge devices and consumer hardware (â‰¥6GB VRAM).

### Three Integrated Modules:

#### ğŸ“š Module 1: Conversational RAG
**Train + Deploy domain-specific chatbots**
- âœ… 13 SLM families (Qwen, Llama, DeepSeek, Gemma, Mistral, SmolLM)
- âœ… QLoRA 4-bit fine-tuning
- âœ… FAISS vector retrieval
- âœ… Live feedback system

#### ğŸ”§ Module 2: LoRA Training Pipeline
**Efficient fine-tuning on consumer GPUs**
- âœ… 4-bit quantized training (6GB VRAM minimum)
- âœ… Multi-model support (13 training scripts)
- âœ… Custom dataset preparation
- âœ… Hyperparameter templates

#### ğŸ” Module 3: Schema-Action Query System
**SQL-like queries without databases using SLMs**
- âœ… Natural language â†’ Structured queries
- âœ… Multi-table auto-JOIN
- âœ… 3B model (vs 20B+ competitors)
- âœ… Direct CSV/Excel querying

---

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EdgeLLM Framework                          â”‚
â”‚          Full-Stack Small Language Model Suite                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Module 1:   â”‚  â”‚  Module 2:   â”‚  â”‚   Module 3:      â”‚   â”‚
â”‚  â”‚  RAG System  â”‚  â”‚  LoRA Train  â”‚  â”‚  Query Pipeline  â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚                  â”‚   â”‚
â”‚  â”‚ â€¢ Retrieval  â”‚  â”‚ â€¢ 13 Models  â”‚  â”‚ â€¢ NL2Query      â”‚   â”‚
â”‚  â”‚ â€¢ Inference  â”‚  â”‚ â€¢ 4-bit QLoRAâ”‚  â”‚ â€¢ Auto-JOIN     â”‚   â”‚
â”‚  â”‚ â€¢ Feedback   â”‚  â”‚ â€¢ Custom Dataâ”‚  â”‚ â€¢ CSV/Excel     â”‚   â”‚
â”‚  â”‚ â€¢ Live Updateâ”‚  â”‚ â€¢ Templates  â”‚  â”‚ â€¢ 3B SLM        â”‚   â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚         Unified Deployment Interface (Streamlit)          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸŒŸ Why EdgeLLM?

### The Small Language Model Revolution

**Large LMs (GPT-4, Claude) vs Small LMs (0.5B-14B)**

| Aspect | Large LMs | EdgeLLM (Small LMs) |
|--------|-----------|---------------------|
| **Cost** | $10-100 per 1M tokens | $0 (self-hosted) |
| **Latency** | 500-2000ms | 50-200ms |
| **Privacy** | Cloud-based | 100% local |
| **Hardware** | API only | Consumer GPU |
| **Customization** | Limited | Full fine-tuning |
| **Scalability** | Pay per use | Unlimited |

### Our Value Proposition

**Not just smaller models** â€” A complete development stack:
1. **Train** your own SLM (Module 2: LoRA)
2. **Enhance** with knowledge retrieval (Module 1: RAG)
3. **Query** structured data (Module 3: Schema-Action)
4. **Deploy** with production UI (Streamlit)

---

## ğŸ“Š Supported Small Language Models

| Model Family | Parameters | Script | Training VRAM | Use Case |
|-------------|-----------|--------|---------------|----------|
| **Qwen** | 0.5B-14B | `train_qwen_lora*.py` | 6GB-16GB | General purpose |
| **DeepSeek** | 1.5B-14B | `train_deepseek_lora*.py` | 6GB-20GB | Reasoning tasks |
| **Llama** | 1B-8B | `train_llama_lora*.py` | 6GB-16GB | Instruction following |
| **Gemma** | 4B | `train_gemma_lora.py` | 8GB | Balanced performance |
| **Mistral** | 7B | `train_mistral_lora.py` | 12GB | Advanced reasoning |
| **SmolLM** | 1.7B | `train_smollm_lora.py` | 6GB | Ultra-efficient |

**Key Features:**
- âœ… All support 4-bit QLoRA training
- âœ… FAISS RAG integration ready
- âœ… Multi-language capable
- âœ… Edge deployment optimized
